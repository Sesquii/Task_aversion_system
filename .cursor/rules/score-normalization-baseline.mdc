---
description: Score normalization patterns for converting raw metrics to 0-100 scale based on baseline performance
globs: ["backend/analytics.py", "backend/*_manager.py", "docs/*score*.md"]
alwaysApply: true
---

# Score Normalization & Baseline-Relative Scoring Rules

## Core Principle: Points vs Scores

**Points** = Raw, unnormalized values (can be any range, task-specific, absolute values)
**Scores** = Normalized values on 0-100 scale, relative to baseline performance (comparable across tasks/users)

### Naming Conventions

- Use `*_points` or raw metric names for unnormalized values
- Use `*_score` for normalized 0-100 values
- Use `baseline_*` or `avg_*` for baseline/reference values

**Examples:**
- `relief_points` or `actual_relief` → raw relief value (0-10 or 0-100, absolute)
- `relief_score` → normalized relief (0-100, relative to baseline)
- `baseline_aversion` or `avg_aversion` → baseline reference value

## Score Normalization Patterns

### 1. Baseline-Relative Normalization (Preferred)

Normalize scores relative to user's baseline performance:

```python
def normalize_to_baseline(current_value: float, baseline_value: float, 
                          min_score: float = 0.0, max_score: float = 100.0) -> float:
    """
    Normalize a metric to 0-100 scale relative to baseline.
    
    Formula: score = 50 + ((current - baseline) / baseline) * 50
    - current == baseline → score = 50 (neutral)
    - current == 2x baseline → score = 100 (max)
    - current == 0 → score = 0 (min)
    
    Args:
        current_value: Current metric value (raw)
        baseline_value: Baseline/reference value (raw)
        min_score: Minimum normalized score (default: 0.0)
        max_score: Maximum normalized score (default: 100.0)
    
    Returns:
        Normalized score (0-100), with 50 = baseline performance
    """
    if baseline_value <= 0:
        return 50.0  # Neutral if no baseline
    
    # Calculate percentage change from baseline
    ratio = current_value / baseline_value
    
    # Normalize: baseline (1.0) = 50, 2x baseline (2.0) = 100, 0 = 0
    normalized = 50.0 + ((ratio - 1.0) * 50.0)
    
    # Clamp to valid range
    return max(min_score, min(max_score, normalized))
```

**Use cases:**
- Relief scores (normalize against avg_relief_score)
- Stress efficiency (normalize against avg_stress_efficiency)
- Work volume (normalize against avg_work_volume)
- Any metric where personal baseline matters more than absolute values

### 2. Objective Metric Normalization

For metrics with objective evaluation criteria (not just relative to baseline):

```python
def normalize_objective_metric(raw_value: float, 
                               min_possible: float, 
                               max_possible: float,
                               optimal_value: Optional[float] = None) -> float:
    """
    Normalize based on objective criteria.
    
    Args:
        raw_value: Raw metric value
        min_possible: Minimum possible value (objective)
        max_possible: Maximum possible value (objective)
        optimal_value: Optimal target value (if None, uses max_possible)
    
    Returns:
        Normalized score (0-100)
    """
    if min_possible >= max_possible:
        return 50.0  # Invalid range, return neutral
    
    optimal = optimal_value if optimal_value is not None else max_possible
    
    # Linear normalization to 0-100
    if raw_value <= min_possible:
        return 0.0
    elif raw_value >= optimal:
        return 100.0
    else:
        # Linear interpolation
        return ((raw_value - min_possible) / (optimal - min_possible)) * 100.0
```

**Use cases:**
- Task completion rate (0-100% completion)
- Time tracking consistency (0-100% coverage)
- Sleep duration (objective optimal: 7-8 hours)

### 3. Hybrid Normalization (Baseline + Objective Bounds)

Combine baseline-relative with objective bounds:

```python
def normalize_hybrid(current_value: float, 
                     baseline_value: float,
                     min_objective: float,
                     max_objective: float) -> float:
    """
    Normalize using both baseline and objective bounds.
    
    Formula: 
    - Calculate baseline-relative score (50 = baseline)
    - Apply objective bounds (can't score > 100 for impossible values)
    - Apply objective floor (can't score < 0 for impossible values)
    
    Returns:
        Normalized score (0-100)
    """
    # Start with baseline-relative normalization
    baseline_score = normalize_to_baseline(current_value, baseline_value)
    
    # Apply objective bounds
    if current_value < min_objective:
        # Below objective minimum → penalty
        objective_penalty = ((min_objective - current_value) / min_objective) * 50.0
        baseline_score = max(0.0, baseline_score - objective_penalty)
    
    if current_value > max_objective:
        # Above objective maximum → cap at 100 (or apply penalty if over-optimal)
        baseline_score = min(100.0, baseline_score)
    
    return baseline_score
```

## Relief Score Normalization

### Current State
- Relief is stored as raw values (0-10 or 0-100 scale, absolute)
- Used directly in calculations without baseline normalization
- Should be converted to baseline-relative scores

### Implementation Pattern

```python
def calculate_relief_score(actual_relief_points: float, 
                          avg_relief_points: float) -> float:
    """
    Convert raw relief points to normalized relief score (0-100).
    
    Normalization:
    - avg_relief (baseline) = 50 (neutral)
    - 2x baseline = 100 (excellent)
    - 0 = 0 (poor)
    
    Args:
        actual_relief_points: Raw relief value (0-10 or 0-100)
        avg_relief_points: Average relief (baseline, same scale)
    
    Returns:
        Normalized relief score (0-100)
    """
    # Ensure same scale (normalize 0-10 to 0-100 if needed)
    if actual_relief_points <= 10 and avg_relief_points <= 10:
        actual_relief_points *= 10.0
        avg_relief_points *= 10.0
    
    return normalize_to_baseline(actual_relief_points, avg_relief_points)
```

### Usage in Analytics

```python
# In analytics calculations, always normalize relief:
actual_relief_points = row.get('actual_relief', 0)  # Raw value
avg_relief_points = completed_instances['relief_score'].mean()  # Baseline
relief_score = calculate_relief_score(actual_relief_points, avg_relief_points)
```

## Baseline Calculation Patterns

### Rolling Baseline (Time-Window Based)

```python
def calculate_rolling_baseline(df: pd.DataFrame, 
                               metric_column: str,
                               days: int = 30,
                               exclude_today: bool = True) -> float:
    """
    Calculate rolling baseline for a metric.
    
    Args:
        df: DataFrame with metric values
        metric_column: Column name containing metric
        days: Number of days to include in baseline
        exclude_today: Whether to exclude today's data
    
    Returns:
        Baseline value (average over time window)
    """
    cutoff_date = datetime.now() - timedelta(days=days)
    if exclude_today:
        today = datetime.now().date()
        baseline_df = df[
            (df['completed_at_dt'] >= cutoff_date) & 
            (df['completed_at_dt'].dt.date < today)
        ]
    else:
        baseline_df = df[df['completed_at_dt'] >= cutoff_date]
    
    return baseline_df[metric_column].mean()
```

### Task-Type Baseline

```python
def calculate_task_type_baseline(df: pd.DataFrame,
                                 metric_column: str,
                                 task_type: str,
                                 days: int = 30) -> float:
    """
    Calculate baseline for specific task type.
    
    Useful for normalizing work tasks vs self-care tasks separately.
    """
    task_df = df[df['task_type'].str.lower() == task_type.lower()]
    return calculate_rolling_baseline(task_df, metric_column, days)
```

## Migration Strategy

### Phase 1: Add Normalization Functions
1. Add `normalize_to_baseline()` to `analytics.py`
2. Add `calculate_relief_score()` wrapper
3. Keep existing raw values for backward compatibility

### Phase 2: Update Score Calculations
1. Identify all score calculations using raw values
2. Add baseline calculation for each metric
3. Apply normalization functions
4. Update method names: `*_points` → normalized `*_score`

### Phase 3: Update Data Storage
1. Store both raw values (`*_points`) and normalized scores (`*_score`)
2. Update column names where needed
3. Update UI to display normalized scores

### Phase 4: Documentation
1. Document normalization approach for each metric
2. Update API documentation
3. Create migration guide

## Code Examples

### Before (Raw Values)

```python
# OLD: Using raw relief directly
relief = float(actual_dict.get('actual_relief', 0))
net_wellbeing = relief - stress_level
```

### After (Normalized Scores)

```python
# NEW: Normalize relief to baseline-relative score
relief_points = float(actual_dict.get('actual_relief', 0))
avg_relief_points = self._calculate_baseline_relief(days=30)
relief_score = normalize_to_baseline(relief_points, avg_relief_points)

# Use normalized score in calculations
net_wellbeing = relief_score - stress_level
```

## Key Rules

1. **Always normalize to 0-100 scale** for any metric labeled as "score"
2. **Use baseline-relative normalization** for subjective metrics (relief, stress, aversion)
3. **Use objective normalization** for metrics with clear criteria (completion rate, time tracking)
4. **Store both raw and normalized values** during migration period
5. **Document normalization approach** for each metric
6. **Use consistent naming**: `*_points` for raw, `*_score` for normalized
7. **Calculate baselines over appropriate time windows** (typically 30 days)
8. **Handle edge cases**: missing baseline → return neutral (50), zero baseline → return neutral
9. **Consider task-type-specific baselines** when metrics vary significantly by task type
10. **Maintain backward compatibility** during migration

## Testing Patterns

```python
def test_normalize_to_baseline():
    """Test baseline-relative normalization."""
    # Baseline = 50
    assert normalize_to_baseline(50.0, 50.0) == 50.0  # At baseline
    assert normalize_to_baseline(100.0, 50.0) == 100.0  # 2x baseline
    assert normalize_to_baseline(0.0, 50.0) == 0.0  # Zero
    assert normalize_to_baseline(25.0, 50.0) == 25.0  # Half baseline
```

## References

- See `docs/execution_module_v1.0.md` for execution score normalization patterns
- See `docs/composite_score_system.md` for composite score normalization
- See `docs/overall_improvement_ratio.md` for improvement-based scoring
